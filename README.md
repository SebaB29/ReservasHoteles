# 游낃 ReservasHoteles  
**Trabajo Pr치ctico para la materia Organizaci칩n de Datos (95.58)**

## 游논 Integrantes  
| Nombre                      | Github                                   |
|-----------------------------|------------------------------------------|
| Sebasti치n Brizuela          | [SebaB29](https://github.com/SebaB29)    |
| Lucia Agha Zadeh Dehdeh     | [Lucia-azd](https://github.com/Lucia-azd)|
| Juan Sebasti치n Del R칤o      | [S2JuanS2](https://github.com/S2JuanS2)  |

## 游닆 Descripci칩n  
Competencia de Kaggle que consiste en obtener una predicci칩n sobre si una reserva de hotel ser치 cancelada o no.

<p align="justify">
Se realiz칩 un an치lisis exploratorio de los datos de muestra (<i>CHP1</i>) utilizando herramientas proporcionadas por las librer칤as: <b>Pandas</b>, <b>Matplotlib</b>, <b>Seaborn</b>, <b>Numpy</b> y <b>Scipy</b>, adem치s de un archivo con informaci칩n sobre los datos proporcionado por la C치tedra.
</p>

### 游댌 Modelos Predictivos Utilizados  
Se exploraron distintos modelos predictivos para practicar su utilizaci칩n:
* **DecisionTreeClassifier**
* **RandomForestClassifier**
* **KNeighborsClassifier**
* **SVC**
* **XGB**
* **VotingClassifier**
* **StackingClassifier**
* **Redes Neuronales**

## 游닆 Enunciado
<p align="justify">
Los conjuntos de datos a utilizar, <i>hotels_train</i> y <i>hotels_test</i>, se encuentran disponibles en la competencia de Kaggle y deber치n descargarlos desde all칤. All칤 mismo encontrar치n un archivo de ejemplo de c칩mo se deben subir las soluciones.
Se deber치n explorar los datos de train, realizar ingenier칤a de caracter칤sticas y entrenar modelos de clasificaci칩n para poder predecir si una reserva ser치 cancelada: el target ser치 la variable <i>is_canceled</i>. Las tareas de preprocesamiento deber치n replicarse en los datos de test, ya que ser치 necesario obtener las predicciones sobre el conjunto de evaluaci칩n y subirlas a Kaggle.
</p>

### Etapas a Desarrollar  
1. **An치lisis Exploratorio y Preprocesamiento de Datos**
   - Exploraci칩n Inicial
   - Visualizaci칩n de los datos
   - An치lisis de Datos Faltantes
   - Detecci칩n de Valores At칤picos

2. **Clasificaci칩n - Entrenamiento y Predicci칩n**
   - 츼rbol de decisi칩n
   - Modelos de ensamble (KNN, SVC, RF, XGBoost)
   - Redes Neuronales

## 游늵 Reporte Final  

### Introducci칩n

<p align="justify">
Se realiz칩 un an치lisis exploratorio sobre un dataset de reservas de hoteles, que tiene 31 columnas y 61,913 filas. A trav칠s de an치lisis y visualizaciones, se determinaron las variables relevantes. Luego se pas칩 al preprocesamiento de datos, donde se detectaron columnas con datos faltantes y outliers, a los cuales se les aplic칩 su correspondiente tratamiento. Se exploraron distintos modelos de clasificaci칩n en la b칰squeda de mejores m칠tricas para predecir si la reserva fue cancelada o no.
</p>

### Cuadro de Resultados  
| CHP | Modelo             | F1 Score | Precision Test | Recall Test | Accuracy | Kaggle   |
|-----|--------------------|----------|----------------|-------------|----------|----------|
| 2   | 츼rbol              | 0.85184  | 0.84518        | 0.83861     | 0.84570  | 0.84082  |
| 3   | Stacking (Mejor)   | 0.86116  | 0.86498        | 0.86884     | 0.86379  | 0.86193  |
| 4   | Red Neuronal       | 0.82974  | 0.76997        | 0.89957     | 0.81459  | 0.80829  |

### Conclusiones Generales
<p align="justify">
A partir del an치lisis exploratorio realizado en el dataset de reservas de hoteles, se han obtenido diversas conclusiones. En primer lugar, se realiz칩 un an치lisis de los datos que incluy칩 un preprocesamiento que aport칩 una buena base para obtener buenas predicciones, incluyendo la gesti칩n de datos faltantes y la identificaci칩n y tratamiento de valores at칤picos. 
</p>

- En t칠rminos de simplicidad y velocidad de entrenamiento, **XGBoost** se destac칩 como el modelo m치s sencillo y r치pido de entrenar, obteniendo el segundo mejor resultado en Kaggle.
- El modelo **Stacking** demostr칩 ser el m치s efectivo en la competencia de Kaggle.

<p align="justify">
En resumen, el an치lisis exploratorio y las decisiones tomadas en el preprocesamiento fueron fundamentales para mejorar las predicciones de los modelos. Aunque consideramos que nuestros modelos son buenos para ser los primeros que realizamos, es importante seguir explorando y experimentando con diferentes enfoques para lograr mejoras en la performance predictiva de nuestros modelos.
</p>

## 游늯 Licencia  
Este proyecto est치 bajo la licencia MIT. Para m치s detalles, consulta el archivo [LICENSE](./LICENSE).
